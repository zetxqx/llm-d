apiVersion: apps/v1
kind: Deployment
metadata:
  name: qwen-model-32b
spec:
  replicas: 8
  selector:
    matchLabels:
      app: qwen-model-32b
  template:
    metadata:
      labels:
        app: qwen-model-32b
    spec:
      containers:
        - name: vllm
          image: "vllm/vllm-openai:v0.11.0"
          imagePullPolicy: IfNotPresent
          command: ["python3", "-m", "vllm.entrypoints.openai.api_server"]
          args:
          - "--model"
          - "Qwen/Qwen3-32B"
          - "--tensor-parallel-size"
          - "2"
          - "--gpu-memory-utilization"
          - "0.65"
          - "--kv-transfer-config"
          - '{"kv_connector":"OffloadingConnector","kv_role":"kv_both","kv_connector_extra_config":{"num_cpu_blocks":41000}}'
          - "--port"
          - "8000"
          - "--max-num-seq"
          - "1024"
          - "--compilation-config"
          - '{"cudagraph_mode": "PIECEWISE"}'
          env:
            - name: VLLM_USE_V1
              value: "1"
            - name: PORT
              value: "8000"
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: llm-d-hf-token
                  key: HF_TOKEN
            - name: LD_LIBRARY_PATH
              value: "/usr/local/nvidia/lib64"
          ports:
            - containerPort: 8000
              name: http
              protocol: TCP
          lifecycle:
            preStop:
              sleep:
                seconds: 30
          livenessProbe:
            httpGet:
              path: /health
              port: http
              scheme: HTTP
            periodSeconds: 1
            successThreshold: 1
            failureThreshold: 5
            timeoutSeconds: 1
          readinessProbe:
            httpGet:
              path: /health
              port: http
              scheme: HTTP
            periodSeconds: 1
            successThreshold: 1
            failureThreshold: 1
            timeoutSeconds: 1
          startupProbe:
            failureThreshold: 600
            initialDelaySeconds: 2
            periodSeconds: 1
            httpGet:
              path: /health
              port: http
              scheme: HTTP
          resources:
            limits:
              nvidia.com/gpu: 2
            requests:
              nvidia.com/gpu: 2
              memory: 400G
          volumeMounts:
            - mountPath: /data
              name: data
            - mountPath: /dev/shm
              name: shm
      restartPolicy: Always

      enableServiceLinks: false

      terminationGracePeriodSeconds: 130

      volumes:
        - name: data
          emptyDir: {}
        - name: shm
          emptyDir:
            medium: Memory