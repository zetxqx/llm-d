apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: vllm-llama-3-70b-instruct
spec:
  parentRefs:
  - group: gateway.networking.k8s.io
    kind: Gateway
    name: cpu-offloading-inference-gateway
  rules:
    - backendRefs:
      - group: inference.networking.x-k8s.io
        kind: InferencePool
        name: vllm-llama-3-70b-instruct
        port: 8000
        weight: 1
      # Inference requests can take a very long time to finish.
      # Explicitly setting to 0s to disable timeout on the HTTPRoute.
      timeouts:
        backendRequest: 0s
        request: 0s
      matches:
      - path:
          type: PathPrefix
          value: /
      
