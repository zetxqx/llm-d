# Using Ubuntu 22.04 to match upstream vLLM compilation environment with glibc 2.35 for now.
FROM ubuntu:22.04 AS base-common

ARG CACHE_BUSTER
RUN if [ -n "${CACHE_BUSTER}" ]; then \
        echo "$CACHE_BUSTER" > /tmp/builder-buster; \
    fi;

ARG PYTHON_VERSION=3.12
ARG PIP_EXTRA_INDEX_URL="https://download.pytorch.org/whl/cpu/"
ARG VLLM_REPO="https://github.com/vllm-project/vllm.git"
# Pin to a commit SHA1/Tag
ARG VLLM_COMMIT_SHA="d7de043d55d1dd629554467e23874097e1c48993"
ARG TARGETARCH
# Support for building with non-AVX512 vLLM
ARG VLLM_CPU_DISABLE_AVX512=0
# Support for building with AVX512BF16 ISA
ARG VLLM_CPU_AVX512BF16=0
# Support for building with AVX512VNNI ISA
ARG VLLM_CPU_AVX512VNNI=0

RUN apt clean && apt-get update -y && \
    apt-get install -y --no-install-recommends --fix-missing \
    curl \
    git \
    wget \
    vim

RUN apt-get install -y ca-certificates && update-ca-certificates

WORKDIR /workspace/vllm

# Install system dependencies and uv
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
    --mount=type=cache,target=/var/lib/apt,sharing=locked \
    apt-get update -y \
    && apt-get install -y --no-install-recommends \
        sudo curl git wget vim ca-certificates \
        gcc-12 g++-12 ccache \
        libtcmalloc-minimal4 libnuma-dev \
        ffmpeg libsm6 libxext6 libgl1 jq lsof \
    && update-ca-certificates \
    && update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12 \
    && curl -LsSf https://astral.sh/uv/install.sh | sh

# TODO: hookup CPU image to our SCCACHE instance
ENV CCACHE_DIR=/root/.cache/ccache
ENV CMAKE_CXX_COMPILER_LAUNCHER=ccache

ENV PATH="/root/.local/bin:$PATH"
ENV VIRTUAL_ENV="/opt/venv"
ENV UV_PYTHON_INSTALL_DIR=/opt/uv/python
RUN uv venv --python ${PYTHON_VERSION} --seed ${VIRTUAL_ENV}

ENV PATH="$VIRTUAL_ENV/bin:$PATH"

# Clone vLLM and build for CPU
WORKDIR /workspace
RUN --mount=type=cache,target=/var/cache/git \
    git clone "${VLLM_REPO}" /workspace/vllm && \
    git -C /workspace/vllm config --system --add safe.directory /workspace/vllm && \
    git -C /workspace/vllm fetch --depth=1 origin "${VLLM_COMMIT_SHA}" || true && \
    git -C /workspace/vllm checkout -q "${VLLM_COMMIT_SHA}"

# Install Python dependencies
WORKDIR /workspace/vllm
ENV PIP_EXTRA_INDEX_URL=${PIP_EXTRA_INDEX_URL}
ENV UV_EXTRA_INDEX_URL=${PIP_EXTRA_INDEX_URL}
ENV UV_INDEX_STRATEGY="unsafe-best-match"
ENV UV_LINK_MODE="copy"
ENV UV_HTTP_TIMEOUT=500
ENV UV_HTTP_RETRIES=10
RUN --mount=type=cache,target=/root/.cache/uv \
    uv pip install --upgrade pip && \
    uv pip install -r requirements/cpu.txt -v

RUN echo 'ulimit -c 0' >> ~/.bashrc

ENV TARGETARCH=${TARGETARCH}

# Only for runtime consistency
ENV VLLM_CPU_DISABLE_AVX512=${VLLM_CPU_DISABLE_AVX512}
ENV VLLM_CPU_AVX512BF16=${VLLM_CPU_AVX512BF16}
ENV VLLM_CPU_AVX512VNNI=${VLLM_CPU_AVX512VNNI}

######################### x86_64 BASE IMAGE #########################
FROM base-common AS base-amd64

ENV LD_PRELOAD="/usr/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4:/opt/venv/lib/libiomp5.so"

######################### arm64 BASE IMAGE #########################
FROM base-common AS base-arm64

ENV LD_PRELOAD="/usr/lib/aarch64-linux-gnu/libtcmalloc_minimal.so.4"

######################### BUILD IMAGE #########################
# Build vLLM wheel from source
###############################################################
FROM base-${TARGETARCH} AS vllm-build

ARG CACHE_BUSTER
RUN if [ -n "${CACHE_BUSTER}" ]; then \
        echo "$CACHE_BUSTER" > /tmp/builder-buster; \
    fi;

# Reduce parallel job from 32(vllm prev-0.13.0 pytorch2.8) to 6 due to vllm v0.14.0(pytorch2.9+)
# resource requirements
# Lower value to prevent runner OOM/timeout during wheel build
ARG max_jobs=6

WORKDIR /workspace/vllm

RUN --mount=type=cache,target=/root/.cache/uv \
   uv pip install -r requirements/cpu-build.txt

RUN --mount=type=cache,target=/root/.cache/uv \
    --mount=type=cache,target=/root/.cache/ccache \
    --mount=type=cache,target=/workspace/vllm/.deps,sharing=locked \
    MAX_JOBS=${max_jobs} VLLM_TARGET_DEVICE=cpu \
    python3 setup.py bdist_wheel --dist-dir=dist --py-limited-api=cp38

######################### RUNTIME IMAGE #########################
# Final runtime image with install vLLM wheel + NIXL + UCX
#################################################################
FROM vllm-build

ENV LD_LIBRARY_PATH="/usr/local/lib:/usr/lib:${LD_LIBRARY_PATH}"

RUN --mount=type=bind,from=vllm-build,src=/workspace/vllm/dist,target=dist \
    --mount=type=cache,target=/root/.cache/uv \
    uv pip install dist/*.whl

# install OTEL packages to enable tracing
COPY docker/packages/common/runtime-otel-package-requirements.txt /workspace/runtime-otel-package-requirements.txt
RUN --mount=type=cache,target=/root/.cache/uv \
    uv pip install -r /workspace/runtime-otel-package-requirements.txt


# Install pkg-config
RUN apt-get update && apt-get install -y --no-install-recommends pkg-config \
 && rm -rf /var/lib/apt/lists/*

# Copy install_nixl.py script
COPY docker/scripts/cpu/install_nixl.py /workspace/install_nixl.py

# Install nixl + UCX
RUN python3 /workspace/install_nixl.py

WORKDIR /workspace
ENTRYPOINT ["python", "-m", "vllm.entrypoints.openai.api_server"]
